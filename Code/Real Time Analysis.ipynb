{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f8face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyaudio\n",
    "import librosa\n",
    "import pywt\n",
    "import wave \n",
    "import joblib\n",
    "from scipy.stats import skew,kurtosis,entropy\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "import nolds\n",
    "from sklearn.exceptions import InconsistentVersionWarning\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\", category=InconsistentVersionWarning)\n",
    "\n",
    "def record_audio(file_name, duration, sample_rate=44100, chunk_size=1024, format=pyaudio.paInt16, channels=1):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    \n",
    "    stream = audio.open(format=format,\n",
    "                        channels=channels,\n",
    "                        rate=sample_rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk_size)\n",
    "    \n",
    "    frames = []\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    for i in range(0, int(sample_rate / chunk_size * duration)):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio as a .wav file\n",
    "    wf = wave.open(file_name, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(audio.get_sample_size(format))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "# Example usage: Record audio for 5 seconds and save it as \"recorded_audio.wav\"\n",
    "record_audio(\"recorded_audio.wav\", duration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183541b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing audio...\n",
      "Finished playing audio.\n"
     ]
    }
   ],
   "source": [
    "def play_audio(file_name):\n",
    "    wf = wave.open(file_name, 'rb')\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    data = wf.readframes(1024)\n",
    "\n",
    "    print(\"Playing audio...\")\n",
    "\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(1024)\n",
    "\n",
    "    print(\"Finished playing audio.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()\n",
    "\n",
    "# Example usage: Play the recorded audio file \"recorded_audio.wav\"\n",
    "play_audio(\"recorded_audio.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02203203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 216)\n",
      "(36, 216)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "\n",
    "    # Extract features\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    \n",
    "    print(mfccs.shape)\n",
    "\n",
    "    # Stack all the features into a single array\n",
    "    features = np.vstack([mfccs, chroma, spectral_centroid, spectral_bandwidth, zero_crossing_rate, rms, spectral_contrast])\n",
    "    #print(features)\n",
    "    return features\n",
    "\n",
    "# Example usage: Extract features from the recorded audio file \"recorded_audio.wav\"\n",
    "file_name = \"recorded_audio.wav\"\n",
    "audio_features = extract_features(file_name)\n",
    "print(audio_features.shape)  # Print the shape of the extracted features array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c16efe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_app_tkeo_mean(audio_signal, num_segments=10):\n",
    "    segment_size = len(audio_signal) // num_segments\n",
    "    app_tkeo_mean_values = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_index = i * segment_size\n",
    "        end_index = start_index + segment_size\n",
    "\n",
    "        # Extract the segment of the signal\n",
    "        segment = audio_signal[start_index:end_index]\n",
    "\n",
    "        # Calculate the Teager-Kaiser energy operator (TKEO) mean for the segment\n",
    "        tkeo = segment[1:-1] ** 2 - segment[:-2] * segment[2:]\n",
    "        app_tkeo_mean = np.mean(tkeo)\n",
    "\n",
    "        # Append the TKEO mean to the list of values\n",
    "        app_tkeo_mean_values.append(app_tkeo_mean)\n",
    "        \n",
    "    return app_tkeo_mean_values\n",
    "\n",
    "\n",
    "def calculate_app_tkeo_std(audio_signal, num_segments=10):\n",
    "    segment_size = len(audio_signal) // num_segments\n",
    "    app_tkeo_std_values = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_index = i * segment_size\n",
    "        end_index = start_index + segment_size\n",
    "\n",
    "        # Extract the segment of the signal\n",
    "        segment = audio_signal[start_index:end_index]\n",
    "\n",
    "        # Calculate the Teager-Kaiser energy operator (TKEO) mean for the segment\n",
    "        tkeo = segment[1:-1] ** 2 - segment[:-2] * segment[2:]\n",
    "        app_tkeo_std = np.std(tkeo)\n",
    "\n",
    "        # Append the TKEO mean to the list of values\n",
    "        app_tkeo_std_values.append(app_tkeo_std)\n",
    "        \n",
    "    return app_tkeo_std_values\n",
    "\n",
    "def compute_ppe(audio_signal, sample_rate):\n",
    "    # Compute the autocorrelation of the audio signal\n",
    "    autocorr = librosa.autocorrelate(audio_signal)\n",
    "\n",
    "    # Remove the first element (which is the autocorrelation at lag 0)\n",
    "    autocorr = autocorr[1:]\n",
    "\n",
    "    # Compute the normalized autocorrelation\n",
    "    norm_autocorr = autocorr / np.max(autocorr)\n",
    "\n",
    "    # Compute the Pitch Period Entropy (PPE)\n",
    "    ppe = -np.sum(norm_autocorr * np.log(np.maximum(norm_autocorr, np.finfo(float).eps)))\n",
    "\n",
    "    return ppe\n",
    "\n",
    "def compute_jitter(audio_signal):\n",
    "    diff = np.diff(audio_signal)  # Compute differences between consecutive samples\n",
    "    jitter = np.mean(np.abs(diff))  # Compute mean absolute difference\n",
    "    return jitter\n",
    "\n",
    "def compute_shimmer_features(audio_signal, sample_rate):\n",
    "    # Compute peak amplitudes\n",
    "    peaks, _ = find_peaks(audio_signal)\n",
    "    peak_amplitudes = audio_signal[peaks]\n",
    "\n",
    "    # Compute differences between consecutive peak amplitudes\n",
    "    peak_diffs = np.diff(peak_amplitudes)\n",
    "\n",
    "    # Compute local shimmer\n",
    "    loc_shimmer = np.mean(np.abs(peak_diffs))\n",
    "\n",
    "    # Compute local shimmer in decibels\n",
    "    loc_db_shimmer = np.mean(20 * np.log10(np.abs(peak_diffs) + 1e-9))  # Adding a small constant value\n",
    "\n",
    "    # Compute APQ for 3 periods\n",
    "    apq3_shimmer = np.mean(np.abs(np.diff(peak_diffs[:3])))\n",
    "\n",
    "    # Compute APQ for 5 periods\n",
    "    apq5_shimmer = np.mean(np.abs(np.diff(peak_diffs[:5])))\n",
    "\n",
    "    # Compute APQ for 11 periods\n",
    "    apq11_shimmer = np.mean(np.abs(np.diff(peak_diffs[:11])))\n",
    "\n",
    "    # Compute DDA shimmer\n",
    "    dda_shimmer = np.mean(np.abs(np.diff(peak_diffs[1::2]))) - np.mean(np.abs(np.diff(peak_diffs[::2])))\n",
    "\n",
    "    return loc_shimmer, loc_db_shimmer, apq3_shimmer, apq5_shimmer, apq11_shimmer, dda_shimmer\n",
    "\n",
    "def compute_features_vocal_fold(file_path):\n",
    "    # Load the audio file\n",
    "    signal, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "    features = {}\n",
    "\n",
    "    # Compute GQ_prc5_95\n",
    "    q95, q5 = np.percentile(signal, [95, 5])\n",
    "    gq_prc5_95 = q95 - q5\n",
    "    features['GQ_prc5_95'] = gq_prc5_95\n",
    "\n",
    "    # Compute GQ_std_cycle_open and GQ_std_cycle_closed\n",
    "    # These are just placeholders, you need to implement the actual computation based on your requirements\n",
    "    gq_std_cycle_open = np.std(signal)\n",
    "    gq_std_cycle_closed = np.std(signal)\n",
    "    features['GQ_std_cycle_open'] = gq_std_cycle_open\n",
    "    features['GQ_std_cycle_closed'] = gq_std_cycle_closed\n",
    "\n",
    "    # Compute GNE_mean and GNE_std\n",
    "    gne_mean = np.mean(np.abs(np.diff(signal)))\n",
    "    gne_std = np.std(np.abs(np.diff(signal)))\n",
    "    features['GNE_mean'] = gne_mean\n",
    "    features['GNE_std'] = gne_std\n",
    "\n",
    "    # Compute GNE_SNR_TKEO and GNE_SNR_SEO\n",
    "    gne_snr_tkeo = np.mean(signal ** 2) / np.mean(np.diff(signal) ** 2)\n",
    "    gne_snr_seo = np.mean(np.abs(signal)) / np.mean(np.abs(np.diff(signal)))\n",
    "    features['GNE_SNR_TKEO'] = gne_snr_tkeo\n",
    "    features['GNE_SNR_SEO'] = gne_snr_seo\n",
    "\n",
    "    # Compute GNE_NSR_TKEO and GNE_NSR_SEO\n",
    "    # These are just placeholders, you need to implement the actual computation based on your requirements\n",
    "    gne_nsr_tkeo = np.mean(signal) / np.mean(np.diff(signal))\n",
    "    gne_nsr_seo = np.mean(signal) / np.mean(np.diff(signal))\n",
    "    features['GNE_NSR_TKEO'] = gne_nsr_tkeo\n",
    "    features['GNE_NSR_SEO'] = gne_nsr_seo\n",
    "\n",
    "    # Compute VFER_mean and VFER_std\n",
    "    vfer_mean = np.mean(np.diff(signal))\n",
    "    vfer_std = np.std(np.diff(signal))\n",
    "    features['VFER_mean'] = vfer_mean\n",
    "    features['VFER_std'] = vfer_std\n",
    "\n",
    "    # Compute VFER_entropy\n",
    "    vfer_entropy = entropy(signal)\n",
    "    features['VFER_entropy'] = vfer_entropy\n",
    "\n",
    "    # Compute VFER_SNR_TKEO and VFER_SNR_SEO\n",
    "    # These are just placeholders, you need to implement the actual computation based on your requirements\n",
    "    vfer_snr_tkeo = np.mean(signal ** 2) / np.mean(np.diff(signal) ** 2)\n",
    "    vfer_snr_seo = np.mean(np.abs(signal)) / np.mean(np.abs(np.diff(signal)))\n",
    "    features['VFER_SNR_TKEO'] = vfer_snr_tkeo\n",
    "    features['VFER_SNR_SEO'] = vfer_snr_seo\n",
    "\n",
    "    # Compute VFER_NSR_TKEO and VFER_NSR_SEO\n",
    "    # These are just placeholders, you need to implement the actual computation based on your requirements\n",
    "    vfer_nsr_tkeo = np.mean(signal) / np.mean(np.diff(signal))\n",
    "    vfer_nsr_seo = np.mean(signal) / np.mean(np.diff(signal))\n",
    "    features['VFER_NSR_TKEO'] = vfer_nsr_tkeo\n",
    "    features['VFER_NSR_SEO'] = vfer_nsr_seo\n",
    "\n",
    "    # Compute IMF_SNR_SEO, IMF_SNR_TKEO, and IMF_SNR_entropy\n",
    "    # These are just placeholders, you need to implement the actual computation based on your requirements\n",
    "    imf_snr_seo = np.mean(np.abs(signal)) / np.mean(np.abs(np.diff(signal)))\n",
    "    imf_snr_tkeo = np.mean(signal ** 2) / np.mean(np.diff(signal) ** 2)\n",
    "    imf_snr_entropy = entropy(signal)\n",
    "    features['IMF_SNR_SEO'] = imf_snr_seo\n",
    "    features['IMF_SNR_TKEO'] = imf_snr_tkeo\n",
    "    features['IMF_SNR_entropy'] = imf_snr_entropy\n",
    "\n",
    "    # Compute IMF_NSR_SEO, IMF_NSR_TKEO, and IMF_NSR_entropy\n",
    "    # These are just placeholders, you need to implement the actual computation based on your requirements\n",
    "    imf_nsr_seo = np.mean(signal) / np.mean(np.abs(np.diff(signal)))\n",
    "    imf_nsr_tkeo = np.mean(signal) / np.mean(np.diff(signal))\n",
    "    imf_nsr_entropy = entropy(signal)\n",
    "    features['IMF_NSR_SEO'] = imf_nsr_seo\n",
    "    features['IMF_NSR_TKEO'] = imf_nsr_tkeo\n",
    "    features['IMF_NSR_entropy'] = imf_nsr_entropy\n",
    "\n",
    "    return features\n",
    "\n",
    "def compute_audio_features_mfccs(file_path):\n",
    "    # Load the audio file\n",
    "    audio_signal, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "    features = {}\n",
    "\n",
    "    # Compute mean_Log_energy\n",
    "    mean_log_energy = np.mean(np.log(np.abs(audio_signal) ** 2 + 1e-9))  # Adding a small constant\n",
    "    features['mean_Log_energy'] = mean_log_energy\n",
    "\n",
    "    # Compute mean and standard deviation of MFCC coefficients (0th to 12th)\n",
    "    mfcc_coeffs = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13)\n",
    "    for i in range(13):\n",
    "        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(i+1, 'th')  # Get the appropriate suffix\n",
    "        features[f'mean_MFCC_{i+1}{suffix}_coef'] = np.mean(mfcc_coeffs[i])\n",
    "        features[f'std_MFCC_{i+1}{suffix}_coef'] = np.std(mfcc_coeffs[i])\n",
    "\n",
    "    # Compute mean and standard deviation of delta log energy and delta coefficients\n",
    "    rms_energy = np.sqrt(np.mean(audio_signal ** 2))\n",
    "    features['rms_energy'] = rms_energy\n",
    "    delta_log_energy = librosa.feature.delta(np.log(np.abs(audio_signal)+ 1e-9))\n",
    "    delta_mfcc = librosa.feature.delta(mfcc_coeffs)\n",
    "    for i in range(13):\n",
    "        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(i+1, 'th')  # Get the appropriate suffix\n",
    "        features[f'mean_delta_log_energy'] = np.mean(delta_log_energy[i])\n",
    "        features[f'std_delta_log_energy'] = np.std(delta_log_energy[i])\n",
    "        features[f'mean_{i+1}{suffix}_delta'] = np.mean(delta_mfcc[i])\n",
    "        features[f'std_{i+1}{suffix}_delta'] = np.std(delta_mfcc[i])\n",
    "\n",
    "    # Compute mean and standard deviation of delta-delta log energy and delta-delta coefficients\n",
    "    delta_delta_log_energy = librosa.feature.delta(delta_log_energy)\n",
    "    delta_delta_mfcc = librosa.feature.delta(delta_mfcc)\n",
    "    for i in range(13):\n",
    "        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(i+1, 'th')  # Get the appropriate suffix\n",
    "        features[f'mean_delta_delta_log_energy'] = np.mean(delta_delta_log_energy[i])\n",
    "        features[f'std_delta_delta_log_energy'] = np.std(delta_delta_log_energy[i])\n",
    "        features[f'mean_{i+1}{suffix}_delta_delta'] = np.mean(delta_delta_mfcc[i])\n",
    "        features[f'std_{i+1}{suffix}_delta_delta'] = np.std(delta_delta_mfcc[i])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_features_wavelet(file_path):\n",
    "    # Load the audio file\n",
    "    audio_signal, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    app_tkeo_mean_values = calculate_app_tkeo_mean(audio_signal)\n",
    "    app_tkeo_std_values = calculate_app_tkeo_std(audio_signal)\n",
    "    \n",
    "    # Energy (Ea)\n",
    "    energy = np.sum(audio_signal ** 2) / len(audio_signal)\n",
    "    features['Ea'] = energy\n",
    "\n",
    "    # Delta Coefficients (Ed_1_coef, Ed_2_coef, ..., Ed_10_coef)\n",
    "    mfcc = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    for i in range(min(10, delta_mfcc.shape[0])):\n",
    "        features[f'Ed_{i+1}_coef'] = np.mean(delta_mfcc[i])\n",
    "\n",
    "    # Shannon Entropy (det_entropy_shannon_1_coef, ..., det_entropy_shannon_10_coef)\n",
    "    entropy_bw = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate)\n",
    "    for i in range(min(10, entropy_bw.shape[1])):\n",
    "        features[f'det_entropy_shannon_{i+1}_coef'] = np.mean(entropy_bw[:, i])\n",
    "\n",
    "    # Additional features\n",
    "    envelope = np.abs(librosa.core.stft(audio_signal))\n",
    "\n",
    "    # Take the logarithm of the envelope\n",
    "    log_envelope = np.log1p(envelope)\n",
    "\n",
    "    # Log Entropy (det_entropy_log_1_coef, ..., det_entropy_log_10_coef)\n",
    "    for i in range(10):\n",
    "        entropy_log = entropy(log_envelope, axis=0, base=2)\n",
    "        features[f'det_entropy_log_{i+1}_coef'] = np.mean(entropy_log)\n",
    "\n",
    "    # TKEO Mean (det_TKEO_mean_1_coef, ..., det_TKEO_mean_10_coef)\n",
    "    tkeo = librosa.onset.onset_strength(y=audio_signal, sr=sample_rate)\n",
    "    for i in range(10):\n",
    "        features[f'det_TKEO_mean_{i+1}_coef'] = np.mean(tkeo)\n",
    "\n",
    "    # TKEO Standard Deviation (det_TKEO_std_1_coef, ..., det_TKEO_std_10_coef)\n",
    "    for i in range(10):\n",
    "        features[f'det_TKEO_std_{i+1}_coef'] = np.std(tkeo)\n",
    "\n",
    "    app_entropy = librosa.feature.spectral_flatness(y=audio_signal)\n",
    "    num_frames = app_entropy.shape[1]  # Get the number of frames\n",
    "    for i in range(min(10, num_frames)):\n",
    "        features[f'app_entropy_shannon_{i+1}_coef'] = np.mean(app_entropy[:, i] ** 2)\n",
    "        \n",
    "    # App Entropy (app_entropy_log_1_coef, ..., app_entropy_log_10_coef)\n",
    "    app_entropy = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate, centroid=None)\n",
    "    num_frames = app_entropy.shape[1]  # Get the number of frames\n",
    "    for i in range(min(10, num_frames)):\n",
    "        features[f'app_entropy_log_{i+1}_coef'] = np.mean(app_entropy[:, i] ** 2)\n",
    "\n",
    "    # LT TKEO Mean (det_LT_TKEO_mean_1_coef, ..., det_LT_TKEO_mean_10_coef)\n",
    "    lt_tkeo = librosa.feature.tempogram(y=audio_signal, sr=sample_rate)\n",
    "    \n",
    "    num_frames = lt_tkeo.shape[1]  # Get the number of frames\n",
    "    for i in range(min(10, num_frames)):\n",
    "        features[f'det_LT_TKEO_mean_{i+1}_coef'] = np.mean(lt_tkeo[:, i])\n",
    "    \n",
    "    # App TKEO Mean (app_TKEO_mean_1_coef, ..., app_TKEO_mean_10_coef)\n",
    "    #num_frames = len(app_tkeo_mean)\n",
    "    #for i in range(min(10, num_frames)):\n",
    "    for i in range(10):\n",
    "        features[f'app_det_TKEO_mean_{i+1}_coef'] = app_tkeo_mean_values[i]\n",
    "\n",
    "    # App TKEO Standard Deviation (app_TKEO_std_1_coef, ..., app_TKEO_std_10_coef)\n",
    "    #num_frames = len(app_tkeo_std)\n",
    "    #for i in range(min(10, num_frames)):\n",
    "    for i in range(10):\n",
    "        features[f'app_TKEO_std_{i+1}_coef'] = app_tkeo_std_values[i]\n",
    "\n",
    "\n",
    "    # Additional features based on Ea\n",
    "    # Ea2\n",
    "    energy_squared = energy ** 2\n",
    "    features['Ea2'] = energy_squared\n",
    "\n",
    "    # Additional features based on Ed_2_coef\n",
    "    # Ed2_1_coef, Ed2_2_coef, ..., Ed2_10_coef\n",
    "    for i in range(10):\n",
    "        features[f'Ed2_{i+1}_coef'] = np.mean(delta_mfcc[i] ** 2)\n",
    "\n",
    "    # Additional features based on det_entropy_shannon_1_coef\n",
    "    # det_LT_entropy_shannon_1_coef, ..., det_LT_entropy_shannon_10_coef\n",
    "    for i in range(10):\n",
    "        features[f'det_LT_entropy_shannon_{i+1}_coef'] = np.mean(entropy_bw[:, i] ** 2)\n",
    "\n",
    "    # Additional features based on det_LT_entropy_log_1_coef\n",
    "    # det_LT_entropy_log_1_coef, ..., det_LT_entropy_log_10_coef\n",
    "    for i in range(10):\n",
    "        features[f'det_LT_entropy_log_{i+1}_coef'] = np.mean(entropy_log ** 2)\n",
    "\n",
    "    for i in range(10):\n",
    "        features[f'det_LT_TKEO_mean_{i+1}_coef'] = np.mean(lt_tkeo[i])\n",
    "        \n",
    "    for i in range(10):\n",
    "        features[f'det_LT_TKEO_std_{i+1}_coef'] = np.std(lt_tkeo[i])\n",
    "\n",
    "    # Additional features based on app_entropy_shannon_1_coef\n",
    "    # app_LT_entropy_shannon_1_coef, ..., app_LT_entropy_shannon_10_coef\n",
    "    for i in range(min(10, app_entropy.shape[1])):\n",
    "        features[f'app_LT_entropy_shannon_{i+1}_coef'] = np.mean(app_entropy[:, i] ** 2)\n",
    "\n",
    "    # Additional features based on app_entropy_log_1_coef\n",
    "    # app_LT_entropy_log_1_coef, ..., app_LT_entropy_log_10_coef\n",
    "    for i in range(min(10, app_entropy.shape[1])):\n",
    "        features[f'app_LT_entropy_log_{i+1}_coef'] = np.mean(app_entropy[:, i] ** 2)\n",
    "\n",
    "    # Additional features based on app_det_TKEO_mean_1_coef\n",
    "    # app_LT_TKEO_mean_1_coef, ..., app_LT_TKEO_mean_10_coef\n",
    "    for i in range(10):\n",
    "        features[f'app_LT_TKEO_mean_{i+1}_coef'] = np.mean(tkeo ** 2)\n",
    "\n",
    "    # Additional features based on app_TKEO_std_1_coef\n",
    "    # app_TKEO_std_1_coef, ..., app_TKEO_std_10_coef\n",
    "    for i in range(10):\n",
    "        features[f'app_LT_TKEO_std_{i+1}_coef'] = np.std(tkeo ** 2)\n",
    "\n",
    "    return features\n",
    "\n",
    "def shannon_entropy(signal):\n",
    "    # Compute histogram of the signal\n",
    "    hist, _ = np.histogram(signal, bins='auto', density=True)\n",
    "\n",
    "    # Calculate Shannon entropy\n",
    "    entropy_value = -np.sum(hist * np.log2(hist + np.finfo(float).eps))  # Add epsilon for numerical stability\n",
    "\n",
    "    return entropy_value\n",
    "\n",
    "def calculate_tqwt_features(file_path):\n",
    "    # Load the audio file\n",
    "    audio_signal, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Calculate TQWT coefficients using Stationary Wavelet Transform\n",
    "    tqwt_coeffs = pywt.swt(audio_signal, 'db1', level=5)\n",
    "\n",
    "    # Calculate TQWT energy coefficients\n",
    "    for i in range(36):\n",
    "        if i < len(tqwt_coeffs):\n",
    "            features[f'tqwt_energy_dec_{i+1}'] = np.sum(tqwt_coeffs[i])\n",
    "            features[f'tqwt_entropy_shannon_dec_{i+1}'] = shannon_entropy(tqwt_coeffs[i])\n",
    "            features[f'tqwt_entropy_log_dec_{i+1}'] = np.mean(librosa.feature.spectral_centroid(y=np.array(tqwt_coeffs[i]), sr=sample_rate))\n",
    "            features[f'tqwt_TKEO_mean_dec_{i+1}'] = np.mean(tqwt_coeffs[i])\n",
    "            features[f'tqwt_TKEO_std_dec_{i+1}'] = np.std(tqwt_coeffs[i])\n",
    "            features[f'tqwt_medianValue_dec_{i+1}'] = np.median(tqwt_coeffs[i])\n",
    "            features[f'tqwt_meanValue_dec_{i+1}'] = np.mean(tqwt_coeffs[i])\n",
    "            features[f'tqwt_stdValue_dec_{i+1}'] = np.std(tqwt_coeffs[i])\n",
    "            features[f'tqwt_minValue_dec_{i+1}'] = np.min(tqwt_coeffs[i])\n",
    "            features[f'tqwt_maxValue_dec_{i+1}'] = np.max(tqwt_coeffs[i])\n",
    "            features[f'tqwt_skewnessValue_dec_{i+1}'] = skew(tqwt_coeffs[i] + np.finfo(float).eps)  # Add epsilon for regularization\n",
    "            features[f'tqwt_kurtosisValue_dec_{i+1}'] = kurtosis(tqwt_coeffs[i] + np.finfo(float).eps)  # Add epsilon for regularization\n",
    "        else:\n",
    "            features[f'tqwt_energy_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_entropy_shannon_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_entropy_log_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_TKEO_mean_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_TKEO_std_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_medianValue_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_meanValue_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_stdValue_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_minValue_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_maxValue_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_skewnessValue_dec_{i+1}'] = 0\n",
    "            features[f'tqwt_kurtosisValue_dec_{i+1}'] = 0\n",
    "            \n",
    "    return features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e03b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "84\n",
      "182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisp\\AppData\\Local\\Temp\\ipykernel_11956\\2983828133.py:365: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  features[f'tqwt_skewnessValue_dec_{i+1}'] = skew(tqwt_coeffs[i] + np.finfo(float).eps)  # Add epsilon for regularization\n",
      "C:\\Users\\luisp\\AppData\\Local\\Temp\\ipykernel_11956\\2983828133.py:366: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  features[f'tqwt_kurtosisValue_dec_{i+1}'] = kurtosis(tqwt_coeffs[i] + np.finfo(float).eps)  # Add epsilon for regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n"
     ]
    }
   ],
   "source": [
    "def compute_features(file_path):\n",
    "    # Load the audio file\n",
    "    audio_signal, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "\n",
    "    # PPE (Pitch Period Entropy)\n",
    "    ppe = compute_ppe(audio_signal, sample_rate)\n",
    "\n",
    "    # DFA (Detrended Fluctuation Analysis)\n",
    "    dfa = nolds.dfa(audio_signal)\n",
    "\n",
    "    # RPDE (Recurrence Period Density Entropy)\n",
    "    rpde = 0  # Need to implement this based on specific algorithm\n",
    "\n",
    "    # numPulses, numPeriodsPulses, meanPeriodPulses, stdDevPeriodPulses\n",
    "    num_pulses = 0  # Need to implement this based on specific algorithm\n",
    "    num_periods_pulses = 0  # Need to implement this based on specific algorithm\n",
    "    mean_period_pulses = 0  # Need to implement this based on specific algorithm\n",
    "    std_dev_period_pulses = 0  # Need to implement this based on specific algorithm\n",
    "\n",
    "    # locPctJitter, locAbsJitter, rapJitter, ppq5Jitter, ddpJitter\n",
    "    loc_pct_jitter = compute_jitter(audio_signal)\n",
    "    loc_abs_jitter = compute_jitter(np.abs(audio_signal))\n",
    "    rap_jitter = compute_jitter(np.abs(np.diff(audio_signal)))\n",
    "    ppq5_jitter = compute_jitter(np.diff(audio_signal)**2)\n",
    "    ddp_jitter = compute_jitter(np.abs(np.diff(np.abs(audio_signal))))\n",
    "\n",
    "    # locShimmer, locDbShimmer, apq3Shimmer, apq5Shimmer, apq11Shimmer, ddaShimmer\n",
    "    loc_shimmer,loc_db_shimmer,apq3_shimmer,apq5_shimmer,apq11_shimmer,dda_shimmer = compute_shimmer_features(audio_signal, sample_rate)\n",
    "\n",
    "    # meanAutoCorrHarmonicity, meanNoiseToHarmHarmonicity, meanHarmToNoiseHarmonicity\n",
    "    harmonic, percussive = librosa.effects.hpss(audio_signal)\n",
    "    mean_auto_corr_harmonicity = np.mean(librosa.autocorrelate(harmonic))\n",
    "    mean_noise_to_harm_harmonicity = np.mean(harmonic) / np.mean(percussive)\n",
    "    mean_harm_to_noise_harmonicity = np.mean(percussive) / np.mean(harmonic)\n",
    "     \n",
    "    min_intensity = np.min(audio_signal)\n",
    "    max_intensity = np.max(audio_signal)\n",
    "    mean_intensity = np.mean(audio_signal)\n",
    "    \n",
    "    f1 = np.mean(audio_signal)  # Mean\n",
    "    f2 = np.std(audio_signal)   # Standard deviation\n",
    "    f3 = np.median(audio_signal)  # Median\n",
    "    f4 = np.percentile(audio_signal, 75)  # 75th percentile\n",
    "    \n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio_signal, sr=sample_rate)\n",
    "    b1 = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate)[0]\n",
    "    b2 = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate, p=2)[0]\n",
    "    b3 = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate, p=3)[0]\n",
    "    b4 = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate, p=4)[0]\n",
    "\n",
    "    b1 = b1.mean()\n",
    "    b2 = b2.mean()\n",
    "    b3 = b3.mean()\n",
    "    b4 = b4.mean()\n",
    "    \n",
    "    data = {\n",
    "        'PPE': ppe,\n",
    "        'DFA': dfa,\n",
    "        'RPDE': rpde,\n",
    "        'numPulses': num_pulses,\n",
    "        'numPeriodsPulfses': num_periods_pulses,\n",
    "        'meanPeriodPulses': mean_period_pulses,\n",
    "        'stdDevPeriodPulses': std_dev_period_pulses,\n",
    "        'locPctJitter': loc_pct_jitter,\n",
    "        'locAbsJitter': loc_abs_jitter,\n",
    "        'rapJitter': rap_jitter,\n",
    "        'ppq5Jitter': ppq5_jitter,\n",
    "        'ddpJitter': ddp_jitter,\n",
    "        'locShimmer': loc_shimmer,\n",
    "        'locDbShimmer': loc_db_shimmer,\n",
    "        'apq3Shimmer': apq3_shimmer,\n",
    "        'apq5Shimmer': apq5_shimmer,\n",
    "        'apq11Shimmer': apq11_shimmer,\n",
    "        'ddaShimmer': dda_shimmer,\n",
    "        'meanAutoCorrHarmonicity': mean_auto_corr_harmonicity,\n",
    "        'meanNoiseToHarmHarmonicity': mean_noise_to_harm_harmonicity,\n",
    "        'meanHarmToNoiseHarmonicity': mean_harm_to_noise_harmonicity,\n",
    "        'minIntensity': min_intensity,\n",
    "        'maxIntensity': max_intensity,\n",
    "        'meanIntensity': mean_intensity,\n",
    "        'f1':f1,\n",
    "        'f2':f2,\n",
    "        'f3':f3,\n",
    "        'f4':f4,\n",
    "        'b1':b1,\n",
    "        'b2':b2,\n",
    "        'b3':b3,\n",
    "        'b4':b4\n",
    "    }\n",
    "    \n",
    "    feature_functions = [\n",
    "        compute_features_vocal_fold,\n",
    "        compute_audio_features_mfccs,\n",
    "        calculate_features_wavelet,\n",
    "        calculate_tqwt_features\n",
    "    ]\n",
    "\n",
    "    # Loop through each feature function and merge its result into data\n",
    "    for function in feature_functions:\n",
    "        features = function(file_path)\n",
    "        print(len(features.keys()))\n",
    "        data = {**data, **features}\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Usage example\n",
    "file_path = 'recorded_audio.wav'\n",
    "features = compute_features(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b99aea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Value\n",
      "PPE                        -4253.493773\n",
      "DFA                            0.211547\n",
      "meanHarmToNoiseHarmonicity     0.079955\n",
      "minIntensity                  -0.196198\n",
      "f1                             0.000362\n",
      "f3                             0.000366\n",
      "GNE_mean                       0.000471\n",
      "GNE_SNR_TKEO                  43.405174\n",
      "mean_MFCC_6th_coef              3.81458\n",
      "mean_7th_delta_delta          -0.001767\n",
      "std_MFCC_2nd_coef             63.814266\n",
      "std_delta_delta_log_energy          0.0\n",
      "std_6th_delta_delta            0.231444\n",
      "std_7th_delta_delta            0.228587\n",
      "std_8th_delta_delta            0.200076\n",
      "det_TKEO_std_1_coef            0.557969\n",
      "tqwt_energy_dec_6                     0\n",
      "tqwt_energy_dec_9                     0\n",
      "tqwt_energy_dec_21                    0\n",
      "tqwt_entropy_log_dec_6                0\n",
      "tqwt_entropy_log_dec_12               0\n",
      "tqwt_entropy_log_dec_16               0\n",
      "tqwt_entropy_log_dec_19               0\n",
      "tqwt_entropy_log_dec_25               0\n",
      "tqwt_entropy_log_dec_27               0\n",
      "tqwt_entropy_log_dec_32               0\n",
      "tqwt_TKEO_mean_dec_8                  0\n",
      "tqwt_TKEO_mean_dec_18                 0\n",
      "tqwt_TKEO_mean_dec_25                 0\n",
      "tqwt_TKEO_std_dec_6                   0\n",
      "tqwt_TKEO_std_dec_10                  0\n",
      "tqwt_TKEO_std_dec_11                  0\n",
      "tqwt_TKEO_std_dec_19                  0\n",
      "tqwt_TKEO_std_dec_23                  0\n",
      "tqwt_meanValue_dec_4           0.000362\n",
      "tqwt_stdValue_dec_25                  0\n",
      "tqwt_stdValue_dec_26                  0\n",
      "tqwt_stdValue_dec_27                  0\n",
      "tqwt_stdValue_dec_34                  0\n",
      "tqwt_minValue_dec_7                   0\n",
      "tqwt_minValue_dec_17                  0\n",
      "tqwt_maxValue_dec_11                  0\n",
      "tqwt_skewnessValue_dec_26             0\n",
      "tqwt_kurtosisValue_dec_27             0\n",
      "Não tem doença de Parkinson\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame.from_dict(features, orient='index', columns=['Value'])\n",
    "\n",
    "\n",
    "model = joblib.load('D:/Dissertation/Models/XGBoostFeatureSelection/SVM.joblib')\n",
    "feature_names = pd.read_csv(\"D:/Dissertation/Models/XGBoostFeatureSelection/SVM_feature_names.csv\")\n",
    "\n",
    "\n",
    "# Assuming features is your dictionary\n",
    "data = pd.DataFrame.from_dict(features, orient='index', columns=['Value'])\n",
    "\n",
    "# Ensure the index is sorted to avoid potential KeyError\n",
    "data = data.sort_index()\n",
    "\n",
    "# Now you can proceed with accessing the selected features\n",
    "selected_features = feature_names['Feature Names'].tolist()\n",
    "selected_features = [feat for feat in selected_features if feat in data.index]\n",
    "\n",
    "if selected_features:\n",
    "    # Access the selected features from the DataFrame\n",
    "    data_selected = data.loc[selected_features]\n",
    "    print(data_selected)\n",
    "else:\n",
    "    print(\"No selected features found in the DataFrame.\")\n",
    "    \n",
    "X_pred = pd.DataFrame(data_selected).transpose()  # Convert data to DataFrame and transpose it\n",
    "prediction = model.predict(X_pred)\n",
    "if prediction == 0:\n",
    "    print(\"Não tem doença de Parkinson\")\n",
    "else:\n",
    "    print(\"Tem doença de Parkinson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c763382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
